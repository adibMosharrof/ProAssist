"""DST ProAssist Dataset for DST Training.

Loads event data generated by sparse_sequence_generator.py.
"""

import json
import logging
from pathlib import Path
from typing import Dict, Any, List
from torch.utils.data import Dataset

logger = logging.getLogger(__name__)


class DSTProAssistDataset(Dataset):
    """Dataset for DST ProAssist DST training.
    
    Loads JSON files with event data where only frames with events
    (speaking or DST updates) are stored.
    
    Expected JSON format:
    [
        {
            "video_uid": str,
            "clip_idx": int,
            "start_frame": int,
            "end_frame": int,
            "events": [
                {
                    "frame_idx": int,
                    "speaking": 0/1,
                    "dst_update": 0/1,
                    "dst_updates": ["S1->start", ...],
                    "response": str or null
                },
                ...
            ],
            ...
        },
        ...
    ]
    """
    
    def __init__(
        self,
        data_path: str,
        dataset_name: str = "assembly101",
        siglip_features_dir: str = None,
    ):
        """Initialize dataset.
        
        Args:
            data_path: Path to JSON file with DST ProAssist data
            dataset_name: Name of dataset (for embedding path construction)
            siglip_features_dir: Path to directory containing SigLIP features (optional filtering)
        """
        self.data_path = Path(data_path)
        self.dataset_name = dataset_name
        
        # Load data
        logger.info(f"Loading DST ProAssist data from {self.data_path}")
        with open(self.data_path, "r") as f:
            raw_data = json.load(f)
            
        # Filter data if siglip_features_dir is provided
        if siglip_features_dir:
            self.data = []
            features_dir = Path(siglip_features_dir)
            logger.info(f"Filtering samples based on feature existence in {features_dir}")
            
            missing_count = 0
            for sample in raw_data:
                clip_id = sample.get("id") or sample.get("video_uid")
                # Construct path to .arrow file (matching collator logic)
                arrow_path = features_dir / dataset_name / "siglip_features" / f"{clip_id}.arrow"
                
                if arrow_path.exists():
                    self.data.append(sample)
                else:
                    missing_count += 1
            
            if missing_count > 0:
                logger.warning(f"âš  Skipped {missing_count} samples due to missing SigLIP features")
        else:
            self.data = raw_data
        
        logger.info(f"Loaded {len(self.data)} clips from {self.data_path}")
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """Get a single sample.
        
        Returns:
            Dict with keys:
                - video_uid: str
                - clip_idx: int
                - start_frame: int
                - end_frame: int
                - events: List[Dict]
                - dataset_name: str (added for embedding loading)
                - id: str (clip ID for embedding lookup)
        """
        sample = self.data[idx].copy()
        
        # Add dataset name for embedding path construction
        sample["dataset_name"] = self.dataset_name
        
        # Add clip ID for embedding lookup
        # Use video_uid + clip_idx as unique identifier
        if "id" not in sample:
            sample["id"] = f"{sample['video_uid']}_{sample.get('clip_idx', 0)}"
        
        return sample
