# üîß PROSPECT DST Training - Implementation Status

**Last Updated:** November 24, 2025  
**Branch:** main  
**Python Environment:** `/u/siddique-d1/adib/ProAssist/.venv/bin/python`

---

## üìã Overview

This document tracks the implementation progress of DST-enhanced training for ProAssist. Use this to resume work from any machine.

**Related Documents:**
- **Implementation Plan:** `6.2-prospect_dst_training_plan.md` (complete design specification)
- **Training Data Spec:** `6.1-prospect_training_data.json` (sample data format)
- **Q&A Session:** `6.1-prospect_training.md` (clarification questions and answers)

---

## ‚úÖ Completed Work

### Phase 1: Data Loading Infrastructure

#### 1.1 Dataset Implementation ‚úì
**File:** `custom/src/prospect/data_sources/dst_training_dataset.py`

**Status:** Core structure complete, but label creation not working

**What Was Implemented:**
```python
class DSTTrainingDataset(Dataset):
    """
    Loads DST-enhanced conversation clips for training.
    Each clip is one training sample.
    """
    
    def __init__(self, data_path, dataset_name, processor, 
                 max_seq_len=4096, neg_frame_sampling_rate=0.5)
    
    def _load_clips(self) -> List[Dict]
        # Loads clips from JSON file
        
    def __getitem__(self, idx) -> Dict
        # Returns: video_uid, clip_idx, frames_file, conversation, 
        #          dst, initial_dst_state, neg_frame_sampling_rate
    
    def load_frames_for_turn(self, frames_file, start_frame, end_frame)
        # On-demand frame loading from arrow files (with caching)
        # NOTE: Not yet integrated into collator
    
    def build_system_prompt(self, dst_steps, initial_dst_state=None)
        # Constructs system prompt with DST steps
        # Format: "You are a proactive assistant... Task Steps: S1: ..., S2: ..."
    
    def get_dst_state_str(self, dst_state) -> str
        # Converts dict to "S1:completed, S2:in_progress" format
    
    def get_dst_update_str(self, dst_update_content) -> str
        # Converts DST update to "S1->start" format
```

**Verified:**
- ‚úì Dataset loads 70 clips from train_training.json
- ‚úì System prompt construction works correctly
- ‚úì DST state/update formatting works
- ‚úì Frame loading logic implemented (not yet used)

#### 1.2 Data Collator Implementation ‚ö†Ô∏è
**File:** `custom/src/prospect/data_sources/dst_training_dataset.py`

**Status:** Structure complete, but label creation is BROKEN

**What Was Implemented:**
```python
class DSTDataCollator:
    """
    Collates batch of clips into tensors for training.
    Based on ProActCollator pattern from mmassist/data/data_collator.py
    """
    
    def __init__(self, tokenizer, processor, chat_formatter=None)
    
    def __call__(self, batch: List[Dict]) -> Dict[str, torch.Tensor]
        # Returns: input_ids, labels, dst_binary_labels, dst_gen_labels,
        #          neg_frame_mask, pos_frame_mask
    
    def _format_conversation(self, conversation, neg_frame_sampling_rate)
        # Formats conversation as text
        # Returns: (formatted_text, learn_ranges)
        
    def _create_labels_from_ranges(self, learn_ranges, offset_mapping, 
                                   input_ids, labels, dst_binary_labels, 
                                   dst_gen_labels)
        # Creates labels from learnable ranges
        
    def _find_token_sequence(self, haystack, needle)
        # Finds token sequence in longer sequence
```

**Verified:**
- ‚úì Collator accepts batches without errors
- ‚úì Returns correct tensor shapes
- ‚úì Conversation formatting works
- ‚úó **CRITICAL ISSUE:** No labels are being created (all -100)

#### 1.3 Training Script Infrastructure ‚úì
**File:** `custom/src/prospect/train/dst_training_prospect.py`

**Status:** Basic structure complete

**What Was Implemented:**
```python
@dataclass
class ModelArguments:
    model_name: str = "HuggingFaceTB/SmolVLM2-2.2B-Instruct"
    use_dst_heads: bool = True
    num_dst_states: int = 10

@dataclass  
class DataArguments:
    data_path: str
    dataset_name: str = "assembly101"
    max_seq_len: int = 4096
    neg_frame_sampling_rate: float = 0.5

@dataclass
class TrainingConfig(TrainingArguments):
    lm_loss_weight: float = 1.0
    dst_binary_weight: float = 1.0
    dst_gen_weight: float = 1.0

def main():
    # Parse args
    # Load processor and model
    # Create datasets (train, val, test)
    # Setup collator
    # Create Trainer
    # Train
```

**Verified:**
- ‚úì Script structure is correct
- ‚úì Uses HuggingFace Trainer (no custom validation loop)
- ‚úó Not yet tested end-to-end

#### 1.4 Test Infrastructure ‚úì
**Files Created:**
- `custom/src/prospect/train/test_dst_setup.py` - Basic smoke test
- `custom/src/prospect/train/test_dst_collator_detailed.py` - Detailed label inspection
- `custom/src/prospect/train/test_dst_debug.py` - Debug conversation formatting

**Test Results:**
```bash
# Basic test passes
PYTHONPATH=/u/siddique-d1/adib/ProAssist:$PYTHONPATH \
.venv/bin/python custom/src/prospect/train/test_dst_setup.py
# Result: ‚úì PASSED (but using dummy data)

# Detailed test reveals issue
PYTHONPATH=/u/siddique-d1/adib/ProAssist:$PYTHONPATH \
.venv/bin/python custom/src/prospect/train/test_dst_collator_detailed.py
# Result: ‚úì PASSED but all labels are 0
#   - LM labels: 0 tokens
#   - DST binary positive: 0 tokens  
#   - DST binary negative: 0 tokens
#   - DST generation labels: 0 tokens
#   - Image tokens: 0 tokens
```

---

## üêõ Current Issues

### Issue #1: Label Creation Not Working (CRITICAL)
**Location:** `DSTDataCollator._create_labels_from_ranges()`

**Problem:**
The collator successfully formats conversations and tokenizes them, but fails to create any labels. All label tensors remain at ignore_id (-100).

**Root Cause Analysis:**
1. **Token Sequence Matching Fails:** The `_find_token_sequence()` method cannot find learnable text in the tokenized sequence
2. **Tokenization Mismatch:** Text tokenized separately (for matching) doesn't match text tokenized as part of full conversation
3. **No Image Tokens:** `<image>` tokens are not appearing in the tokenized sequence (count = 0)

**Evidence from Debug Output:**
```
--- Formatted Conversation ---
Length: 1694 chars
First 500 chars:
You are a helpful and proactive assistant...
DST_UPDATE: S1->start
User: I want to assemble a toy vehicle...
Assistant: Great! Let's get started...

--- Tokenization ---
Num tokens: 472
<image> token ID: 49190
Count in sequence: 0  # ‚Üê NO IMAGE TOKENS!

--- Matching Ranges to Tokens ---
Range 0 (dst_update): chars [128, 138)
  Start matches: 0 tokens  # ‚Üê OFFSET MISMATCH
  Stop matches: 1 tokens
```

**Why This Happens:**
1. Tokenizer's offset_mapping uses character offsets from the tokenized string
2. These offsets don't align with our pre-computed character positions
3. Tokenizer may normalize/modify text (whitespace, special tokens)
4. We're not including `<image>` tokens in conversation formatting (frames turns are skipped)

**Current Approach (Failed):**
```python
# Attempt 1: Use offset_mapping to find char positions
# Problem: Offsets don't match our computed positions

# Attempt 2: Tokenize text separately and find in full sequence  
text_tokens = self.tokenizer.encode(text_to_learn, add_special_tokens=False)
match_pos = self._find_token_sequence(input_ids, text_tokens)
# Problem: Text tokenized separately doesn't match full sequence tokenization
```

### Issue #2: Image Tokens Missing
**Problem:** `<image>` tokens are not appearing in the tokenized conversation

**Why:**
- Conversation formatting includes `<image>` in the text string for 'frames' turns
- But tokenizer may not recognize `<image>` as a special token
- SmolVLM2 processor may handle images differently (via processor, not text)

**Impact:**
- Cannot train DST binary head (no frame tokens to classify)
- Cannot implement negative frame sampling properly
- Frame-based learning will not work

### Issue #3: Frame Loading Not Integrated
**Status:** Frame loading code exists but is not called by collator

**Impact:**
- Training will fail when model expects pixel_values
- Cannot process video frames

---

## üîÑ What Needs to Be Done Next

### Priority 1: Fix Label Creation (CRITICAL)

**Two Possible Approaches:**

#### Option A: Follow ProActCollator Exactly
**Reference:** `mmassist/data/data_collator.py` line 20-100

**Strategy:**
1. Use ProAssist's `MultimodalChat` class for conversation formatting
2. Use `chat_formatter.apply_chat_template()` to format conversation
3. Use `chat_formatter.get_learn_ranges()` to get learnable char ranges
4. Use offset_mapping from tokenizer to map char ranges to token positions
5. Handle image tokens properly using chat_formatter's image token insertion

**Key Insight from ProActCollator:**
```python
# ProActCollator uses learn_ranges from chat_formatter
for learn_r in learn_range:
    if learn_r.start > last_start:
        break
    start = torch.nonzero(offset_mapping[:, 0] == learn_r.start).item()
    if offset_mapping[:, 0][-1] >= learn_r.stop:
        stop = torch.nonzero(offset_mapping[:, 0] == learn_r.stop).item()
    else:
        stop = len(input_ids)
    labels[start - 1 : stop - 1] = input_ids[start:stop]
```

**Why This Will Work:**
- ProActCollator is proven and working in ProAssist
- MultimodalChat handles image token insertion correctly
- offset_mapping alignment is reliable when using the same formatting approach

**Implementation Steps:**
1. Import `MultimodalChat` from `mmassist.model.tokenization_proact`
2. Create chat_formatter instance in `DSTDataCollator.__init__()`
3. Replace `_format_conversation()` to use `chat_formatter.apply_chat_template()`
4. Use `chat_formatter.get_learn_ranges()` instead of custom range tracking
5. Update `_create_labels_from_ranges()` to match ProActCollator's approach
6. Handle DST_UPDATE turns as special assistant turns (custom logic needed)

#### Option B: Simplified Token-Level Approach
**Strategy:**
1. Format full conversation as text (current approach)
2. Tokenize once to get input_ids
3. Decode each token back to text and identify learnable tokens by matching text patterns
4. Mark tokens as learnable based on decoded text

**Why This Might Work:**
- Avoids offset_mapping issues
- Direct token-level labeling
- Simpler to debug

**Why This Is Risky:**
- Decoding tokens is slow
- Text matching is unreliable (tokenization is lossy)
- May not handle image tokens correctly

**Recommendation:** Use Option A (follow ProActCollator exactly)

### Priority 2: Fix Image Token Handling

**Options:**

#### Option 2A: Use Processor for Image Token Insertion
**Strategy:**
1. Pass images to processor during tokenization
2. Let processor handle `<image>` token insertion
3. Similar to how SmolVLM2 handles images in inference

**Implementation:**
```python
# In collator.__call__()
texts = []
images = []

for sample in batch:
    # Format conversation without image tokens
    conv_text = format_conversation_text_only(sample['conversation'])
    texts.append(conv_text)
    
    # Load all frames for this clip
    all_frames = load_all_frames_for_clip(sample)
    images.append(all_frames)

# Process with images
batch = self.processor(
    text=texts,
    images=images,  # Processor inserts image tokens
    return_tensors="pt",
    padding=True,
)
```

#### Option 2B: Register `<image>` as Special Token
**Strategy:**
1. Add `<image>` to tokenizer's vocabulary if not present
2. Ensure tokenizer treats it as a single token

**Implementation:**
```python
# In training script or dataset init
if "<image>" not in processor.tokenizer.vocab:
    processor.tokenizer.add_tokens(["<image>"], special_tokens=True)
    # Resize model embeddings
    model.resize_token_embeddings(len(processor.tokenizer))
```

**Recommendation:** Use Option 2A (let processor handle images)

### Priority 3: Integrate Frame Loading

**What To Do:**
1. Update `DSTDataCollator._format_conversation()` to track which frames are needed
2. Call `dataset.load_frames_for_turn()` for each frames turn
3. Collect all frames into a batch
4. Pass frames to processor or add as `pixel_values` in collator output

**Implementation Note:**
- Need to coordinate with Priority 2 (image token handling)
- May need to restructure collator to handle image loading

### Priority 4: Test End-to-End Training

**Once labels are fixed:**
1. Run small training job (few steps)
2. Verify loss computation works
3. Check tensorboard logs
4. Validate model outputs

**Test Command:**
```bash
cd /u/siddique-d1/adib/ProAssist
PYTHONPATH=/u/siddique-d1/adib/ProAssist:$PYTHONPATH \
.venv/bin/python custom/src/prospect/train/dst_training_prospect.py \
    --data_path custom/outputs/dst_generated/hybrid_dst/2025-11-21/00-30-33_gpt-4o_proassist_50rows/assembly101/ \
    --output_dir custom/outputs/dst_training_test \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --max_steps 10
```

---

## üì¶ Phase 2-5: Remaining Work (Not Started)

### Phase 2: Model Architecture Updates
**File:** `custom/src/prospect/models/dst_smolvlm_with_strategies.py`

**What Needs To Be Done:**
- [ ] Add DST binary head (similar to speaking_decision_head)
- [ ] Modify forward() to support DST generation (reuse LM head)
- [ ] Implement compute_loss() with multi-task losses
- [ ] Handle DST-specific labels

**Status:** Not started

### Phase 3: Multi-Task Loss Implementation
**File:** Custom Trainer or in model's compute_loss()

**What Needs To Be Done:**
- [ ] Implement weighted loss combination:
  - LM loss (language modeling)
  - DST binary loss (should_update_dst)
  - DST generation loss (DST transitions)
- [ ] Add loss logging
- [ ] Support configurable loss weights

**Status:** Not started

### Phase 4: Training Loop
**File:** `custom/src/prospect/train/dst_training_prospect.py`

**What Needs To Be Done:**
- [ ] Finalize TrainingArguments configuration
- [ ] Setup proper checkpointing
- [ ] Add tensorboard logging
- [ ] Configure gradient accumulation, mixed precision
- [ ] Test on GPU

**Status:** Basic structure exists, needs completion

### Phase 5: Evaluation Integration
**File:** Evaluation scripts

**What Needs To Be Done:**
- [ ] Add validation metrics computation
- [ ] Implement compute_metrics() callback
- [ ] Log validation losses
- [ ] Monitor DST prediction accuracy

**Status:** Not started

---

## üóÇÔ∏è File Structure

### Files Modified/Created
```
custom/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ training/
‚îÇ       ‚îú‚îÄ‚îÄ 6.1-prospect_training.md              # Q&A session
‚îÇ       ‚îú‚îÄ‚îÄ 6.1-prospect_training_data.json       # Sample data
‚îÇ       ‚îú‚îÄ‚îÄ 6.2-prospect_dst_training_plan.md     # Implementation plan
‚îÇ       ‚îî‚îÄ‚îÄ 6.3-prospect_dst_implementation_status.md  # This file
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ prospect/
‚îÇ       ‚îú‚îÄ‚îÄ data_sources/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ dst_training_dataset.py          # Dataset + Collator
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ dst_smolvlm_with_strategies.py   # Model (not yet updated)
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ train/
‚îÇ           ‚îú‚îÄ‚îÄ dst_training_prospect.py         # Training script
‚îÇ           ‚îú‚îÄ‚îÄ test_dst_setup.py                # Basic test
‚îÇ           ‚îú‚îÄ‚îÄ test_dst_collator_detailed.py    # Detailed test
‚îÇ           ‚îî‚îÄ‚îÄ test_dst_debug.py                # Debug test
‚îÇ
‚îî‚îÄ‚îÄ outputs/
    ‚îî‚îÄ‚îÄ dst_generated/
        ‚îî‚îÄ‚îÄ hybrid_dst/
            ‚îî‚îÄ‚îÄ 2025-11-21/
                ‚îî‚îÄ‚îÄ 00-30-33_gpt-4o_proassist_50rows/
                    ‚îî‚îÄ‚îÄ assembly101/
                        ‚îú‚îÄ‚îÄ train_training.json   # 70 clips
                        ‚îú‚îÄ‚îÄ val_training.json
                        ‚îî‚îÄ‚îÄ test_training.json
```

### Backup Files Created
- `dst_training_dataset.py.old` - Original dataset implementation
- `dst_training_prospect.py.old` - Original training script

---

## üîç Debug Information

### Environment Setup
```bash
# Python environment
PYTHON=/u/siddique-d1/adib/ProAssist/.venv/bin/python

# Set PYTHONPATH
export PYTHONPATH=/u/siddique-d1/adib/ProAssist:$PYTHONPATH

# Run tests
$PYTHON custom/src/prospect/train/test_dst_setup.py
$PYTHON custom/src/prospect/train/test_dst_collator_detailed.py
$PYTHON custom/src/prospect/train/test_dst_debug.py
```

### Key Dependencies
- torch (GPU version)
- transformers (HuggingFace)
- datasets (HuggingFace)
- SmolVLM2-2.2B-Instruct model
- pyarrow (for arrow file loading)

### Data Paths
```python
DATA_ROOT = "custom/outputs/dst_generated/hybrid_dst/2025-11-21/00-30-33_gpt-4o_proassist_50rows/assembly101/"
TRAIN_FILE = f"{DATA_ROOT}/train_training.json"
VAL_FILE = f"{DATA_ROOT}/val_training.json"
TEST_FILE = f"{DATA_ROOT}/test_training.json"
```

### Model Configuration
```python
MODEL_NAME = "HuggingFaceTB/SmolVLM2-2.2B-Instruct"
MAX_SEQ_LEN = 4096
BATCH_SIZE = 2
GRAD_ACCUM_STEPS = 8
LEARNING_RATE = 1e-5
NEG_FRAME_SAMPLING_RATE = 0.5
```

---

## üìö Reference Material

### ProAssist Code to Study
1. **ProActCollator:** `mmassist/data/data_collator.py`
   - Shows how to use offset_mapping correctly
   - Handles learnable range marking
   - Image token insertion

2. **MultimodalChat:** `mmassist/model/tokenization_proact.py`
   - Chat template formatting
   - Learn range calculation
   - Image token handling

3. **ProAssist Training:** `mmassist/train/train.py`
   - Training loop setup
   - Loss computation
   - Metrics logging

### Key Patterns from ProAssist
```python
# 1. Learnable range creation (from MultimodalChat.get_learn_ranges)
for turn in conversation:
    if turn["role"] == "assistant":
        learn_range = range(offset, offset + len(input_str))
        learn_ranges.append(learn_range)
    elif turn["role"] == "frames":
        # Calculate image token positions
        learn_ranges_img = get_learn_ranges_for_img_tokens(...)

# 2. Label assignment (from ProActCollator)
for learn_r in learn_range:
    start = torch.nonzero(offset_mapping[:, 0] == learn_r.start).item()
    stop = torch.nonzero(offset_mapping[:, 0] == learn_r.stop).item()
    labels[start - 1 : stop - 1] = input_ids[start:stop]

# 3. Binary head masking (from ProActCollator)
img_tokens_mask = batch.input_ids == self.tokenizer.img_token_id
batch["neg_frame_mask"] = (batch_labels == w2t_id) & img_tokens_mask
batch["pos_frame_mask"] = (batch_labels == bor_id) & img_tokens_mask
```

---

## üéØ Next Steps Summary

**For immediate resumption:**

1. **Fix label creation** by implementing Option A (follow ProActCollator exactly)
   - Import MultimodalChat
   - Replace _format_conversation with chat_formatter approach
   - Update _create_labels_from_ranges to match ProActCollator
   - Add DST_UPDATE handling logic

2. **Fix image tokens** by implementing Option 2A (use processor)
   - Load frames in collator
   - Pass to processor with text
   - Let processor insert image tokens

3. **Test thoroughly** with detailed tests
   - Verify labels are created
   - Verify image tokens appear
   - Check label counts match expectations

4. **Run small training job** to verify end-to-end
   - 10 steps, 1 batch size
   - Check loss values
   - Verify no crashes

**Estimated Time:**
- Priority 1 (fix labels): 2-4 hours
- Priority 2 (fix images): 1-2 hours  
- Priority 3 (integrate frames): 1 hour
- Priority 4 (test training): 1 hour
- **Total:** 5-8 hours to get Phase 1 working

Then proceed to Phase 2 (model architecture) and beyond.

---

## üìù Notes

### Design Decisions Made
1. Use structured text for DST (not JSON) - easier for model
2. Keep DST updates minimal (S1->start, not full state)
3. Follow ProAssist training patterns exactly
4. Use HuggingFace Trainer (no custom validation loop)
5. On-demand frame loading (memory efficient)
6. Fixed 50% negative sampling rate

### Things That Work
- Dataset loading from JSON ‚úì
- System prompt construction ‚úì
- DST state/update formatting ‚úì
- Frame loading logic (implemented but unused) ‚úì
- Training script structure ‚úì
- Test infrastructure ‚úì

### Things That Don't Work
- Label creation (critical) ‚úó
- Image token insertion ‚úó
- Frame loading integration ‚úó
- End-to-end training (not tested) ‚úó

### Questions for Later
- Should we use curriculum learning for negative sampling rate?
- How to log DST prediction accuracy during training?
- Should we validate DST state consistency?
- Do we need DST-specific evaluation metrics?

---

**End of Status Document**
